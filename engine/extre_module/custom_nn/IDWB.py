'''   
本文件由BiliBili：魔傀面具整理
engine/extre_module/module_images/CVPR2024-InceptionDWBlock.png  
论文链接：https://arxiv.org/pdf/2303.16900
'''

import os, sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)) + '/../../../..')  
   
import warnings    
warnings.filterwarnings('ignore')  
from calflops import calculate_flops     

import torch
import torch.nn as nn    
from timm.layers import to_2tuple, DropPath

from engine.extre_module.ultralytics_nn.conv import Conv

class InceptionDWConv2d(nn.Module):
    """ Inception depthweise convolution
    """  
    def __init__(self, in_channels, square_kernel_size=3, band_kernel_size=11, branch_ratio=0.125):
        super().__init__()  
        
        gc = int(in_channels * branch_ratio) # channel numbers of a convolution branch
        self.dwconv_hw = nn.Conv2d(gc, gc, square_kernel_size, padding=square_kernel_size//2, groups=gc)   
        self.dwconv_w = nn.Conv2d(gc, gc, kernel_size=(1, band_kernel_size), padding=(0, band_kernel_size//2), groups=gc)
        self.dwconv_h = nn.Conv2d(gc, gc, kernel_size=(band_kernel_size, 1), padding=(band_kernel_size//2, 0), groups=gc)     
        self.split_indexes = (in_channels - 3 * gc, gc, gc, gc)    
        
    def forward(self, x):
        x_id, x_hw, x_w, x_h = torch.split(x, self.split_indexes, dim=1)     
        return torch.cat(    
            (x_id, self.dwconv_hw(x_hw), self.dwconv_w(x_w), self.dwconv_h(x_h)), 
            dim=1,
        )
     
class ConvMlp(nn.Module):     
    """ MLP using 1x1 convs that keeps spatial dims    
    copied from timm: https://github.com/huggingface/pytorch-image-models/blob/v0.6.11/timm/models/layers/mlp.py
    """
    def __init__(     
            self, in_features, hidden_features=None, out_features=None, act_layer=nn.ReLU, 
            norm_layer=None, bias=True, drop=0.):
        super().__init__()
        out_features = out_features or in_features   
        hidden_features = hidden_features or in_features    
        bias = to_2tuple(bias) 

        self.fc1 = nn.Conv2d(in_features, hidden_features, kernel_size=1, bias=bias[0])  
        self.norm = norm_layer(hidden_features) if norm_layer else nn.Identity()  
        self.act = act_layer() 
        self.drop = nn.Dropout(drop)  
        self.fc2 = nn.Conv2d(hidden_features, out_features, kernel_size=1, bias=bias[1])  
     
    def forward(self, x):
        x = self.fc1(x)
        x = self.norm(x)
        x = self.act(x) 
        x = self.drop(x)
        x = self.fc2(x)
        return x   
 
class InceptionDWBlock(nn.Module):
    """ MetaNeXtBlock Block
    Args:
        dim (int): Number of input channels.
        drop_path (float): Stochastic depth rate. Default: 0.0
        ls_init_value (float): Init value for Layer Scale. Default: 1e-6.
    """

    def __init__(
            self,
            in_dim,   
            dim,
            token_mixer=InceptionDWConv2d, 
            norm_layer=nn.BatchNorm2d,   
            mlp_layer=ConvMlp,   
            mlp_ratio=4,
            act_layer=nn.GELU,
            ls_init_value=1e-6,
            drop_path=0.,
   
    ): 
        super().__init__()
        self.token_mixer = token_mixer(dim)  
        self.norm = norm_layer(dim)     
        self.mlp = mlp_layer(dim, int(mlp_ratio * dim), act_layer=act_layer)
        self.gamma = nn.Parameter(ls_init_value * torch.ones(dim)) if ls_init_value else None
        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity() 
    
        self.conv1x1 = Conv(in_dim, dim) if in_dim != dim else nn.Identity() 

    def forward(self, x): 
        x = self.conv1x1(x)
        shortcut = x
        x = self.token_mixer(x)   
        x = self.norm(x)   
        x = self.mlp(x)
        if self.gamma is not None:
            x = x.mul(self.gamma.reshape(1, -1, 1, 1)) 
        x = self.drop_path(x) + shortcut
        return x  
  
if __name__ == '__main__':    
    RED, GREEN, BLUE, YELLOW, ORANGE, RESET = "\033[91m", "\033[92m", "\033[94m", "\033[93m", "\033[38;5;208m", "\033[0m"    
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')   
    batch_size, in_channel, out_channel, height, width = 1, 16, 32, 32, 32
    inputs = torch.randn((batch_size, in_channel, height, width)).to(device)
   
    module = InceptionDWBlock(in_channel, out_channel).to(device)
 
    outputs = module(inputs) 
    print(GREEN + f'inputs.size:{inputs.size()} outputs.size:{outputs.size()}' + RESET)

    print(ORANGE)
    flops, macs, _ = calculate_flops(model=module,    
                                     input_shape=(batch_size, in_channel, height, width),    
                                     output_as_string=True,   
                                     output_precision=4,  
                                     print_detailed=True)  
    print(RESET)